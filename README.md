# ğŸŒ² Implementation of Gradient Boosting Algorithm

This project demonstrates the implementation and evaluation of the **Gradient Boosting algorithm** for both classification and regression tasks using scikit-learn. It applies the model on two popular datasets: **Iris** (for classification) and **California Housing** (for regression).

---

## ğŸ“š Datasets Used

- **Iris Dataset** â€“ Used for classification with `GradientBoostingClassifier`
- **California Housing Dataset** â€“ Used for regression with `GradientBoostingRegressor`

---

## ğŸ“Œ Key Steps

### ğŸ”¹ 1. Classification with Iris Dataset
- Load and explore the dataset using `scikit-learn`
- Split the data into training and testing sets
- Train a `GradientBoostingClassifier`
- Evaluate the model using:
  - Accuracy Score
  - Confusion Matrix
  - Classification Report

### ğŸ”¹ 2. Regression with California Housing Dataset
- Load the dataset and prepare the data
- Split the dataset into train and test sets
- Train a `GradientBoostingRegressor`
- Predict on test set
- Evaluate with **Mean Squared Error (MSE)**

---

## ğŸ“ˆ Sample Results

- **Classification Accuracy**: Achieved using the Iris dataset
- **Mean Squared Error (MSE)**: ~0.294 on the California Housing dataset

---

## ğŸ› ï¸ Libraries Used

- `numpy`
- `pandas`
- `matplotlib`
- `seaborn`
- `scikit-learn`

---

## ğŸ§  Learning Outcome

This project demonstrates:
- The power of ensemble methods like Gradient Boosting
- Practical understanding of both classification and regression using gradient boosting
- Model evaluation with appropriate metrics

---

## ğŸš€ How to Run

1. Clone this repository
2. Ensure the following libraries are installed: `scikit-learn`, `numpy`, `pandas`, `matplotlib`, `seaborn`
3. Run the Python script in a Jupyter Notebook or Python environment

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ¤ Contributions

Feel free to fork the repo, raise issues, or submit pull requests.

