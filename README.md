# 🌲 Implementation of Gradient Boosting Algorithm

This project demonstrates the implementation and evaluation of the **Gradient Boosting algorithm** for both classification and regression tasks using scikit-learn. It applies the model on two popular datasets: **Iris** (for classification) and **California Housing** (for regression).

---

## 📚 Datasets Used

- **Iris Dataset** – Used for classification with `GradientBoostingClassifier`
- **California Housing Dataset** – Used for regression with `GradientBoostingRegressor`

---

## 📌 Key Steps

### 🔹 1. Classification with Iris Dataset
- Load and explore the dataset using `scikit-learn`
- Split the data into training and testing sets
- Train a `GradientBoostingClassifier`
- Evaluate the model using:
  - Accuracy Score
  - Confusion Matrix
  - Classification Report

### 🔹 2. Regression with California Housing Dataset
- Load the dataset and prepare the data
- Split the dataset into train and test sets
- Train a `GradientBoostingRegressor`
- Predict on test set
- Evaluate with **Mean Squared Error (MSE)**

---

## 📈 Sample Results

- **Classification Accuracy**: Achieved using the Iris dataset
- **Mean Squared Error (MSE)**: ~0.294 on the California Housing dataset

---

## 🛠️ Libraries Used

- `numpy`
- `pandas`
- `matplotlib`
- `seaborn`
- `scikit-learn`

---

## 🧠 Learning Outcome

This project demonstrates:
- The power of ensemble methods like Gradient Boosting
- Practical understanding of both classification and regression using gradient boosting
- Model evaluation with appropriate metrics

---

## 🚀 How to Run

1. Clone this repository
2. Ensure the following libraries are installed: `scikit-learn`, `numpy`, `pandas`, `matplotlib`, `seaborn`
3. Run the Python script in a Jupyter Notebook or Python environment

---

## 📄 License

This project is licensed under the [MIT License](LICENSE).

---

## 🤝 Contributions

Feel free to fork the repo, raise issues, or submit pull requests.

